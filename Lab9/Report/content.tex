\documentclass[a4paper]{article}
    \usepackage[UTF8]{ctex}
    \usepackage{minted}
    \usepackage{xcolor}
    \usepackage[colorlinks,linkcolor=black]{hyperref}
    \usepackage[margin=1in]{geometry}
    \usepackage{caption}
    \usepackage{graphicx, subfig}
    \usepackage{float}
    \usepackage{fontspec}
    \usepackage{booktabs}
    \setmainfont{Times New Roman}
    \setmonofont{Consolas}
    \definecolor{bg}{rgb}{0.9,0.9,0.9}
    \usemintedstyle{manni}
    \setminted{
    linenos,
    autogobble,
    breaklines,
    breakautoindent,
    bgcolor=bg,
    numberblanklines=false,
    }

\begin{document}
    \tableofcontents
    \newpage
    \section{实验介绍}
        \subsection{实验内容}
            \subsubsection{实验八}
1.使用Hadoop的示例程序计算圆周率$\pi$,调整maps和samples参数,观察运行时间与计算结果精度变化.

2.计算圆周率$\pi$,使其有效精度达到小数点后5位.
            \subsubsection{实验九}
1.编写mapper.py和reducer.py,计算一篇英文文章中不同字母开头的单词的平均长度.

2.编写mapper.py和reducer.py,实现PageRank算法.每一次map和reduce操作完成PageRank的一次迭代计算.
        \subsection{实验环境}
操作系统:Ubun 18.04 LTS
Python版本:3.7
Hadoop版本:2.2.0
        \subsection{所需技能}
实验八主要在于Hadoop环境的准备,在正确完成了环境配置之后,只需对Hadoop的基本工作方式有所了解即可.

实验九进一步深入Hadoop,需要掌握其文件系统的操作以及map-reduce工作原理.同时,还需要了解基本的PageRank算法原理.
\newpage
    \section{实验过程}
        \subsection{估算圆周率}
Hadoop所提供的示例程序中,使用Quasi-Monte Carlo方法计算圆周率.这种方法在$[0,1]\times[0,1]$的正方形区域中随机产生许多点,然后通过计算这些点与原点的距离,
判断其是否在单位圆中.在大量统计的基础上,便可估算出圆周率的值.

对应Hadoop计算圆周率程序运行的参数,在map操作中,进行Number of Maps次模拟实验,每次实验中随机产生Number of Samples个点,最后在reduce操作中,
汇总计算所有点.那么,根据直觉,Maps数和Samples数的乘积越大,总点数越多,最后的估算结果精度应当越高.至于运行时间,当Samples数较小时,
每次map操作的开销主要在于map本身,而非其中的模拟计算,故运行时间应当主要取决于Maps数.

使用不同的参数运行该程序,每组参数重复三次,结果取平均值,见表\ref{Table1}.观察结果,基本与上述分析相符.同时在表\ref{Table1}的末行,
给出了一种使得$\acute{\pi}$的估算精度达到小数点后5位的方案.
\begin{table*}
\centering
\caption{使用Hadoop计算圆周率}
\begin{tabular}{cccc} 
\toprule
Number of Maps & Number of Samples & Time(s) & $\acute{\pi}$\\
\midrule 
2 & 10 & 20.214 & 3.80000000000000000000\\
5 & 10 & 22.430 & 3.28000000000000000000\\
10 & 10 & 27.392 & 3.20000000000000000000\\
2 & 100 & 17.596 & 3.12000000000000000000\\
10 & 100 & 40.041 & 3.14800000000000000000\\
100 & 1000000 & 310.256 & 3.14159256000000000000\\
\bottomrule 
\end{tabular}
\label{Table1}
\end{table*}
    \subsection{统计平均单词长度}
        \subsubsection{Map}
在mapper.py中,通过\mintinline{python}{sys.stdin}读取由Hadoop传递而来的行文本,对其进行处理:

首先,去除文本中除了26个英文字母外的其他字符,如标点符号及数字,将其用空格替代以便进行单词划分.然后,对于划分出的每个单词,
计算其长度,并输出map的结果(字母转为小写形式),形如:\mintinline{cpp}{<letter> <length>}.代码如下:
\begin{minted}{python}
#!/usr/bin/env python3
import sys
from string import ascii_letters

valid_chars = ascii_letters
for line in sys.stdin:
    stripped_line = "".join([x if x in valid_chars else " " for x in line])
    words_list = stripped_line.split()
    for word in words_list:
        print("{letter}\t{length}".format(
            letter=word[0].lower(), length=len(word)))
\end{minted}
        \subsubsection{Reduce}
在reducer.py中,接受Hadoop通过\mintinline{python}{sys.stdin}传递而来的Map后的临时结果,对其进行合并处理.对于统计
单词平均长度,只需将记录同一字母开头的单词个数以及总长度,最后两者相除,将结果通过\mintinline{python}{print}函数输出到
\mintinline{python}{sys.stdin},Hadoop会将其收集并存入结果文件.
\begin{minted}{python}
#!/usr/bin/env python3
import sys

current_letter = None
current_count = None
current_sum = None

for line in sys.stdin:
    letter, length = line.split()
    length = int(length)
    if letter == current_letter:
        current_sum += length
        current_count += 1
    else:
        if current_letter != None:
            print("{letter}\t{average}".format(
                letter=current_letter, average=current_sum/current_count))
        current_letter, current_count, current_sum = letter, 1, length
if current_letter:
    print("{letter}\t{average}".format(
        letter=current_letter, average=current_sum/current_count))    
\end{minted}

注意在以上的代码中,利用了Hadopp会将Map结果按关键词排序再传递给Reduce的特点,即保证了在遇到一个新的开头字母时,之前的字母
一定已经处理完成.
            \subsubsection{运行结果}
以pg5000.txt作为输入,运行得到结果如下:
\begin{minted}{python}
a   3.3844186012320447
b   4.571903651903652
c   6.565201857806359
d   5.653363797918253
e   6.0105919003115265
f   5.084103179364127
g   5.517767833640431
h   3.902831155521394
i   3.141337386018237
j   4.685469475187433
k   5.132145052243393
l   5.144624981135872
m   4.992715998655261
n   4.329627695292099
o   2.82933814830957
p   6.584160116823433
q   6.113682777399592
r   6.426794468427599
s   5.148828229301456
t   3.636275394148561
u   5.010820244328098
v   5.809677419354839
w   4.46050039135246
x   3.3380281690140845
y   3.664545888341021
z   4.636690647482014
\end{minted}
        \subsection{实现PageRank算法}
            \subsubsection{基本原理}
根据PageRank的公式,一个页面的PageRank值由两部分组成:直接被随机选中的概率,顺着链接被访问到的概率:
$$PR(u) = \frac{1-d}{N} + d\sum_{v\in B_{u}}\frac{PR(v)}{N_{v}}$$
式中$d\in(0,1)$为damping factor,$N$为总网页数,$B_{u}$为所有链接指向u的网页的集合,$N_{v}$为网页v
所包含的链接总数.

可以证明,PageRank是收敛的.那么,可以避免直接求其解析解,而是经过多次迭代,逐渐接近其数值解.而每一次的迭代,可通过
一次Map-Reduce循环来实现.
            \subsubsection{Map}
在mapper.py中,通过\mintinline{python}{sys.stdin}读取输入文件的行文本.但需要格外注意的是,Hadoop可能会将
输入的文件分割为多个部分,分别交由不同的mapper同时处理,也就是说,在mapper.py中,必须假定只能获取到输入文件的一部分,
否则运行结果会出现错误.

因此,需要在mapper.py中设定好具体的网页总数N,而不能在运行时对输入进行统计.此外,为了方便在Reduce
时得到网页所指向的其他网页,还需要将网页间的链接关系作为Map结果输出.如下:
\begin{minted}{python}
#!/usr/bin/env python3
import sys

damping_factor = 0.85
page_num = 4   # or some other number

for line in sys.stdin:
    line = line.split()
    try:
        page_id, initial_prob = int(line[0]), float(line[1])
    except:
        continue
    print("{page} plus {plus}".format(page=page_id, plus=(1-damping_factor)/page_num))
    if len(line) <= 2:  # for pages that link to no other pages
        prob_per_page = initial_prob/(page_num-1) * damping_factor
        for page in range(1, page_num+1):
            if page != page_id:
                print("{page} plus {plus}".format(page=page, plus=prob_per_page))
    else:
        links_list = line[2:]
        print("{page} links".format(page=page_id), *links_list)  
        # print all the links of the current page
        prob_per_link = initial_prob/(len(links_list)) * damping_factor
        for link in links_list:
            print("{page} plus {plus}".format(page=link, plus=prob_per_link))
\end{minted}

对以上程序段稍做说明:对于读入的一行文本,譬如\mintinline{tex}{1 0.25 2 3 4},首先从中提取出1和0.25,分别为当前网页
编号和初始概率,根据PageRank的公式,首先输出\mintinline{tex}{1 plus 0.0375}.然后判断该网页是否有指向其他网页的链接,若无,
则认为其链接了所有网页,故将剩余概率等分给所有其他网页;若有,则先输出其链向的网页\mintinline{tex}{1 links 2 3 4},再将
其概率等分给这些网页.故对于该行文本,所有输出为:
\begin{minted}{tex}
1 plus 0.037500000000000006
1 links 2 3 4
2 plus 0.07083333333333333
3 plus 0.07083333333333333
4 plus 0.07083333333333333
\end{minted}
            \subsubsection{Reduce}
由于在Map操作中,已经充分为Reduce提供了便利,故reducer.py只需要将Map的输出合并,算出网页对应的总概率以及链接关系:
\begin{minted}{python}
#!/usr/bin/env python3
import sys

current_page = None
current_prob = None
current_links = None

for line in sys.stdin:
    line = line.split()
    page, operation_type = int(line[0]), line[1]
    if page != current_page:
        if current_page:
            print(current_page, current_prob, *current_links)
        current_page, current_prob, current_links = page, 0, None
    if operation_type == "links":
        current_links = line[2:]  # note here we don't convert page_id to int
    elif operation_type == "plus":
        current_prob += float(line[2])
if current_page:
    print(current_page, current_prob, *current_links)
\end{minted}
        \subsubsection{Bash脚本}
为了得到PageRank的收敛值,需要多次迭代,即多次Map-Reduce循环.至于迭代的终止条件,最佳的做法是判断迭代后变化量是否足够小,
而在这次实验中,我采取了简易的做法,设定一定的迭代次数后终止.

编写的pagerank.sh如下:
\begin{minted}{sh}
#/bin/bash

hadoop_command='hadoop jar /usr/local/hadoop/share/hadoop/tools/lib/hadoop-streaming-2.2.0.jar -files mapper.py,reducer.py -mapper mapper.py -reducer reducer.py'
mv='hadoop fs -mv '
rm='hadoop fs -rm -r'
cp2local='hadoop fs -copyToLocal '
input='tempinput'

for (( i = 1; i < $1+1; i++ )); do
    echo "Page Rank Iteration $i"
    output="pagerank_tempoutput_$i"
    eval "$hadoop_command -input $input -output $output -jobconf mapred.job.name=\"Page Rank Iteration $i\""
    input=$output
    eval "$rm $input/_SUCCESS"
done

mkdir ~/pagerank_result
eval "$cp2local $output/* ~/pagerank_result"
\end{minted}
        \subsubsection{运行结果}
输入为:
\begin{minted}{tex}
1 0.25 2 3 4
2 0.25 3 4
3 0.25 4
4 0.25 2
\end{minted}

设置迭代次数为3,运行:
\begin{minted}{sh}
./pagerank.sh 3
\end{minted}

则每次迭代后,结果如下:
\begin{minted}{tex}
1 0.037500000000000006 2 3 4    
2 0.3208333333333333 3 4    
3 0.21458333333333335 4 
4 0.42708333333333337 2 

1 0.037500000000000006 2 3 4    
2 0.4111458333333334 3 4    
3 0.18447916666666664 4 
4 0.36687499999999995 2 

1 0.037500000000000006 2 3 4    
2 0.35996875 3 4    
3 0.22286197916666667 4 
4 0.3796692708333333 2  
\end{minted}
\newpage
\section{总结与分析}
编写在Hadoop中运行的程序不同于编写普通的程序.

这一点我一开始并没有充分意识到,因而在实验过程中遇到了一些挫折,调试许久,
通过反复对比输入输出以及输出中间过程量,最终才发现BUG的根源在于我没有完全理解Hadoop的Map-Ruduce工作流程.
譬如,一开始在PageRank的mapper.py中,我通过统计读入的行数来确定总网页数N,并以此输出网页直接被随机选中的概率
$(1-d)/N$,但这种做法在Hadoop中是行不通的,因为Hadoop会将输入文件分割成多个片段,交由不同的mapper并行处理.
所以,必须手动指定N的值,以保证结果的正确.

总而言之,通过这两次实验,我对Hadoop有了基本的认识,收获颇丰.
\end{document}
